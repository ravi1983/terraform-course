Terraform:
    Infrastructure as code
    Automation of infra
    Keeps and maintains state of the infra
    Makes the infra auditable, but checking in to git and doing peer review
    While chef, puppet etc.,focus on installing and configuring the software, terraform creates the underlying infra in say AWS, Azure or other cloud providers
    But works well with config software such as Chef, Puppet after infra is created.

Installation:
    Just unzip and add terraform binary to PATH

Execution:
    Run `terraform init` to download cloud provider details. This is needed for every new directory
    Run `terraform apply` to proceed with creation of resources
    Run `terraform destroy` all the resources created with apply command
    Run `terraform plan` to understand what terraform will do on applying this config. This command does not create any resources.
        Can add option -out <filename> to save the output of plan command to the specified file
    To be safe, it is always recommended to do plan save the output to a file and then do apply on that file.
        terraform plan <filename>; terraform apply <filename>

Variables:
    Everything in one file is not great.
    Add AWS creds in a file that will be added to git repo is not good.
    So we need to save the AWS creds in a separate file and not commit to git.
    We can also define variables to make a template more generic. (e.g., make AMIs as variable since they change with each region)
    Variables make template very generic and hence make it reusable
    Syntax to refer variable in template is ${var.<variable name>} assuming the file that contains the variables in var.tf. Can also be referred like so var.<variable name>
    In var.tf, we can either no assign any value to a variable or provide default values. Default values can be maps.
    Use terraform.tfvard to provide values for all variables defined in var.tf. This file will be added to gitignore.
    Can also split up the template further into provider.tf (refers to AWS variables) and instance.tf (mentions resources that need to be created)
    In the end spliting config in following different templates is ideal:
        terraform.tfvars - Will contains the AWS creds. DO NOT checkin
        vars.tf - Will contain default vars, and empty declaration for vars that will be specified in terraform.tfvars
        provider.tf - Will mention the cloud provider and creds to connect to them
        instance.tf - Will specify the list of resources that need to be created

Provision Software:
    Two way to provision software
        1) Can create customer AMI and bundle software into this image. Can be done using packer.
        2) Boot stnadard AMIs and install software on it. Can be done using file uploads, remote exec, or chef/puppet
            Chef is integrated into terraform
            Can do puppet commands using remote-exec

            File uploads:
             Use provisioner file to upload file. Can be in conjunction with remote-exec to execute a script
             provisioner "file" {
                source = "<source file name>"
                destination = "<dest location>/<dest file name>"
             }
             Will SSH in lunux and WinRM on windows. Need to provide username/password via connection option.
             But when using AWS we will be the keypair for connecting to the created instance


Outputting attributes:
    Can used to print any attribute of the resource that was created
    syntax is:
        output <name> {
            value = <resource_type>.<resource_name>.<attribute>
        }
    These attributes can be queried or outputted
    These attributes can also be used in script!
    very useful to start automation scripts after infra has been created

Local state:
    Keep track of remote state of infra using file called terraform.tfstate
    Also keeps track of previous state using terraform.tfstate.backup
    Whenever apply is executed new terraform.tfstate is created and terraform.tfstate.backup is overwritten
    If remote state changes (say manually done out of terraform context), next apply is executed terraform will correct the infra based on the current state in  terraform.tfstate
    Good idea to add the terraform.tfstate and terraform.tfstate.backup to git so the state can be version controlled and team can collaborate
    local state id fine for smaller projection but for bigger projects we might want to store state in remote

Remote state:
    The state can be saved using backend functionality. Default is 'local backend' which uses the local state file which were covered in local state section
    Other backends used to store state remote is s3 (with locking mechanism using DynamoDB), consul (with locking), and terraform enterprise.
    Benefits:
        Whole team refers a single copy of the state, ande coupled with locking we will not run into conflicts
        Sensitive state data is not added to git.
        Some enhanced backends allow remote operations (Apply executed remote not locally. So the infra can be created sooner, and we do not have to keep the local machine up and running.). Only Terraform enterprise can do this as of now
        Everyone will always have latest version of state
        Avoid commits and pushes of terraform.tfstate
    When using s3 to store remote state, use aws configure to configure aws creds in local machine. Cannot use vars for backend since it is used before initialization (terraform init)
    Not all remotes backends support locking. Only s3 and consul support it.
    Can specify read-only remote state directly in .tf file (datasource)