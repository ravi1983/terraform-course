Terraform:
    Infrastructure as code
    Automation of infra
    Keeps and maintains state of the infra
    Makes the infra auditable, but checking in to git and doing peer review
    While chef, puppet etc.,focus on installing and configuring the software, terraform creates the underlying infra in say AWS, Azure or other cloud providers
    But works well with config software such as Chef, Puppet after infra is created.

Installation:
    Just unzip and add terraform binary to PATH

Execution:
    Run `terraform init` to download cloud provider details. This is needed for every new directory
    Run `terraform apply` to proceed with creation of resources
    Run `terraform destroy` all the resources created with apply command
    Run `terraform plan` to understand what terraform will do on applying this config. This command does not create any resources.
        Can add option -out <filename> to save the output of plan command to the specified file
    To be safe, it is always recommended to do plan save the output to a file and then do apply on that file.
        terraform plan <filename>; terraform apply <filename>

Variables:
    Everything in one file is not great.
    Add AWS creds in a file that will be added to git repo is not good.
    So we need to save the AWS creds in a separate file and not commit to git.
    We can also define variables to make a template more generic. (e.g., make AMIs as variable since they change with each region)
    Variables make template very generic and hence make it reusable
    Syntax to refer variable in template is ${var.<variable name>} assuming the file that contains the variables in var.tf. Can also be referred like so var.<variable name>
    In var.tf, we can either no assign any value to a variable or provide default values. Default values can be maps.
    Use terraform.tfvard to provide values for all variables defined in var.tf. This file will be added to gitignore.
    Can also split up the template further into provider.tf (refers to AWS variables) and instance.tf (mentions resources that need to be created)
    In the end spliting config in following different templates is ideal:
        terraform.tfvars - Will contains the AWS creds. DO NOT checkin
        vars.tf - Will contain default vars, and empty declaration for vars that will be specified in terraform.tfvars
        provider.tf - Will mention the cloud provider and creds to connect to them
        instance.tf - Will specify the list of resources that need to be created

Provision Software:
    Two way to provision software
        1) Can create customer AMI and bundle software into this image. Can be done using packer.
        2) Boot stnadard AMIs and install software on it. Can be done using file uploads, remote exec, or chef/puppet
            Chef is integrated into terraform
            Can do puppet commands using remote-exec

            File uploads:
             Use provisioner file to upload file. Can be in conjunction with remote-exec to execute a script
             provisioner "file" {
                source = "<source file name>"
                destination = "<dest location>/<dest file name>"
             }
             Will SSH in lunux and WinRM on windows. Need to provide username/password via connection option.
             But when using AWS we will be the keypair for connecting to the created instance


Outputting attributes:
    Can used to print any attribute of the resource that was created
    syntax is:
        output <name> {
            value = <resource_type>.<resource_name>.<attribute>
        }
    These attributes can be queried or outputted
    These attributes can also be used in script!
    very useful to start automation scripts after infra has been created

Local state:
    Keep track of remote state of infra using file called terraform.tfstate
    Also keeps track of previous state using terraform.tfstate.backup
    Whenever apply is executed new terraform.tfstate is created and terraform.tfstate.backup is overwritten
    If remote state changes (say manually done out of terraform context), next apply is executed terraform will correct the infra based on the current state in  terraform.tfstate
    Good idea to add the terraform.tfstate and terraform.tfstate.backup to git so the state can be version controlled and team can collaborate
    local state id fine for smaller projection but for bigger projects we might want to store state in remote

Remote state:
    The state can be saved using backend functionality. Default is 'local backend' which uses the local state file which were covered in local state section
    Other backends used to store state remote is s3 (with locking mechanism using DynamoDB), consul (with locking), and terraform enterprise.
    Benefits:
        Whole team refers a single copy of the state, ande coupled with locking we will not run into conflicts
        Sensitive state data is not added to git.
        Some enhanced backends allow remote operations (Apply executed remote not locally. So the infra can be created sooner, and we do not have to keep the local machine up and running.). Only Terraform enterprise can do this as of now
        Everyone will always have latest version of state
        Avoid commits and pushes of terraform.tfstate
    When using s3 to store remote state, use aws configure to configure aws creds in local machine. Cannot use vars for backend since it is used before initialization (terraform init)
    Not all remotes backends support locking. Only s3 and consul support it.
    Can specify read-only remote state directly in .tf file (datasource)

Datasource:
    Provide dynamic information if available from provider
    For e.g., terra exposes the same data available from AWS API (such as list of AMIs/AZs)
    This can be used as input or filter in terraform (such as filter resources based on region)
    Can filter by security group too

Template provider
    Help to create customized config files
    Used to create generic template or init configs
    e.g., Used to pass user-data that depends on other info in terraform. (user-data - used to pass commands that need to be executed by AWS)
    How to create one?
        Create a template file - shell script that needs arguments
        template_file resource - This will load the template file and pass the necessary resource

Other providers
    Terraform supports AWS, GCP, Azure, Digital Ocean, and can support any support any provider that expose API
    The terraform script does not change between providers, only the underlying implementation changes

Modules:
    Can help make code organized and reuse (eg., code to create AWS VPC can be reused across regions)
    Can also help with use of third party modules
    Syntax:
        module <module_name>{
            source = <github or local folder loc>
            <arg1> = <arg1_val>
            <argn> = <argn_val>
        }
    Inside the module folder we will have the similar terraform files (vars, provider, instances etc.,)
    value outputted from the module using the 'Outputting attributes' can be used in the main (caller) module using syntax ${module.<module_name>.<output_var_name>}

Command overview:
    Very focused on resource definitions
    Has limited toolsets (more coming) to modify, import and create these resource definitions

    terraform apply --> Apply states
    terraform destroy --> Destroy states
    terraform fmt --> Format the config files
    get --> download/update modules
    graph --> visual representation of the config or execution plan
    import ADDRESS ID --> Import the infra resource identified with ID and import it into terraform.tfstate with resource id ADDRESS.
                            Useful to import *existing* infra into terraform state. Still need to create resource defs for existing infra before doing the import.
    output --> Output any of the resource
    plan --> shows changes to be made
    push --> Pushes changes to Atlas (Hashicorp's enterprise tool) that can run terraform from centralized server
    refresh --> Find diff with state file and remote state, and refresh infra
    remote --> configure remote state storage
    show --> display human readable state file data
    state --> Advanced state management (e.g., rename resource)
    taint --> Manually mark resource as tainted, and will be destroyed and recreated on next apply
    validate --> Validate the terraform syntax
    untaint --> undo the taint

